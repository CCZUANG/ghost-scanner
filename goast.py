import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import requests
from io import StringIO
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime

# --- 1. é é¢åŸºç¤è¨­å®š ---
st.set_page_config(page_title="å¹½éˆç­–ç•¥æƒæå™¨ (é¡Œæå¿«æœç‰ˆ)", page_icon="ğŸ‘»", layout="wide")

st.title("ğŸ‘» å¹½éˆç­–ç•¥æƒæå™¨ (é¡Œæå¿«æœç‰ˆ)")
st.write("""
**ç­–ç•¥ç›®æ¨™**ï¼šä»¥ **HV ä½æ³¢å‹•** æ’åºï¼Œé–å®š **æ—¥ç·šå¤šé ­ + 4H Uå‹** æ¨™çš„ï¼Œä¸¦æä¾› **ä¸€éµæŸ¥è©¢é¡Œæèˆ‡é¢¨éšª** åŠŸèƒ½ã€‚
""")

# --- 2. å´é‚Šæ¬„ï¼šåƒæ•¸è¨­å®šå€ ---
st.sidebar.header("ğŸ¯ å¸‚å ´èˆ‡æ•¸é‡")
market_choice = st.sidebar.radio(
    "é¸æ“‡æƒæå¸‚å ´", 
    ["S&P 500 (å¤§å‹è‚¡)", "NASDAQ 100 (ç§‘æŠ€è‚¡)", "ğŸ”¥ å…¨ç«åŠ› (å…©è€…å…¨æƒ)"],
    index=2
)
scan_limit = st.sidebar.slider("æƒææ•¸é‡ (å‰ N å¤§)", 50, 600, 200)

# --- æ—¥ç·šè¶¨å‹¢æ¿¾ç¶² ---
st.sidebar.header("ğŸ›¡ï¸ æ—¥ç·šè¶¨å‹¢æ¿¾ç¶²")
check_daily_ma60_up = st.sidebar.checkbox("âœ… å¿…é ˆï¼šæ—¥ç·š 60MA å‘ä¸Š", value=True)
check_price_above_daily_ma60 = st.sidebar.checkbox("âœ… å¿…é ˆï¼šè‚¡åƒ¹ > æ—¥ç·š 60MA", value=True)

st.sidebar.header("âš™ï¸ åŸºç¤ç¯©é¸")
hv_threshold = st.sidebar.slider("HV Rank é–€æª» (è¶Šä½è¶Šå¥½)", 10, 100, 65)
min_vol_m = st.sidebar.slider("æœ€å°æ—¥å‡é‡ (ç™¾è¬è‚¡)", 1, 20, 3) 
min_volume_threshold = min_vol_m * 1000000

st.sidebar.header("ğŸ“ˆ 4å°æ™‚ Uå‹æˆ°æ³•")
enable_u_logic = st.sidebar.checkbox("âœ… å•Ÿç”¨ã€ŒUå‹æ•¸å­¸æ“¬åˆã€", value=True)
dist_threshold = st.sidebar.slider("è·é›¢ 4H 60MA ç¯„åœ (%)", 0.0, 50.0, 8.0, step=0.5)

if enable_u_logic:
    u_sensitivity = st.sidebar.slider("Uå‹æ•æ„Ÿåº¦ (Lookback)", 20, 60, 30)
    min_curvature = st.sidebar.slider("æœ€å°å½æ›²åº¦", 0.0, 0.1, 0.003, format="%.3f")
else:
    u_sensitivity = 30
    min_curvature = 0.003

st.sidebar.markdown("---")
max_workers = st.sidebar.slider("ğŸš€ å¹³è¡Œé‹ç®—æ ¸å¿ƒæ•¸", 1, 32, 16)

# --- ç”¢æ¥­ç¿»è­¯å­—å…¸ (æ“´å……ç‰ˆ) ---
# å°‡ key å…¨éƒ¨è½‰ç‚ºå°å¯«ä»¥åˆ©æ¯”å°
INDUSTRY_MAP = {
    "technology": "ç§‘æŠ€æ¥­",
    "software": "è»Ÿé«”",
    "semiconductors": "åŠå°é«”",
    "financial": "é‡‘è",
    "banks": "éŠ€è¡Œ",
    "credit": "ä¿¡è²¸",
    "healthcare": "é†«ç™‚ä¿å¥",
    "biotechnology": "ç”Ÿç‰©ç§‘æŠ€",
    "consumer cyclical": "éå¿…éœ€æ¶ˆè²»",
    "auto": "æ±½è»Š",
    "energy": "èƒ½æº",
    "oil": "çŸ³æ²¹",
    "industrials": "å·¥æ¥­",
    "aerospace": "èˆªå¤ªè»å·¥",
    "communication": "é€šè¨Š",
    "internet": "ç¶²è·¯",
    "utilities": "å…¬ç”¨äº‹æ¥­",
    "real estate": "æˆ¿åœ°ç”¢",
    "reit": "æˆ¿åœ°ç”¢ä¿¡è¨—",
    "basic materials": "åŸç‰©æ–™",
    "entertainment": "å¨›æ¨‚",
    "beverages": "é£²æ–™",
    "retail": "é›¶å”®",
    "insurance": "ä¿éšª",
    "telecom": "é›»ä¿¡",
    "asset management": "è³‡ç”¢ç®¡ç†"
}

def translate_industry(eng_industry):
    if not eng_industry or eng_industry == "N/A":
        return "æœªçŸ¥"
    
    # è½‰å°å¯«ä¸¦å»é™¤å‰å¾Œç©ºç™½
    target = str(eng_industry).lower().strip()
    
    # 1. å˜—è©¦å®Œå…¨åŒ¹é…
    if target in INDUSTRY_MAP:
        return INDUSTRY_MAP[target]
    
    # 2. å˜—è©¦éƒ¨åˆ†é—œéµå­—åŒ¹é… (åªè¦åŒ…å«é—œéµå­—å°±ç¿»è­¯)
    for key, value in INDUSTRY_MAP.items():
        if key in target:
            return value
            
    # 3. çœŸçš„ç¿»ä¸å‡ºä¾†ï¼Œå›å‚³åŸæ–‡çš„é¦–å­—å¤§å¯«
    return target.title()

# --- 3. æ ¸å¿ƒå‡½æ•¸ ---

@st.cache_data(ttl=3600)
def get_sp500_tickers():
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        response = requests.get(url, headers=headers)
        df = pd.read_html(StringIO(response.text))[0]
        tickers = df['Symbol'].tolist()
        return [t.replace('.', '-') for t in tickers]
    except:
        return []

@st.cache_data(ttl=3600)
def get_nasdaq100_tickers():
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        url = "https://en.wikipedia.org/wiki/Nasdaq-100"
        response = requests.get(url, headers=headers)
        dfs = pd.read_html(StringIO(response.text))
        for df in dfs:
            if 'Ticker' in df.columns:
                tickers = df['Ticker'].tolist()
                return [t.replace('.', '-') for t in tickers]
            elif 'Symbol' in df.columns:
                tickers = df['Symbol'].tolist()
                return [t.replace('.', '-') for t in tickers]
        return []
    except:
        return []

def get_combined_tickers(choice, limit):
    sp500 = []
    nasdaq = []
    
    if "S&P" in choice or "å…¨ç«åŠ›" in choice:
        sp500 = get_sp500_tickers()
    
    if "NASDAQ" in choice or "å…¨ç«åŠ›" in choice:
        nasdaq = get_nasdaq100_tickers()
    
    combined = list(set(sp500 + nasdaq))
    
    if not combined:
        return ['TSM', 'NVDA', 'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'TSLA', 'AMD', 'NFLX', 'PLTR', 'LUNR', 'COIN', 'MSTR', 'QQQ', 'SPY']
    
    return combined[:limit]

def analyze_u_shape(ma_series):
    try:
        y = ma_series.values
        x = np.arange(len(y))
        coeffs = np.polyfit(x, y, 2)
        a, b, c = coeffs
        
        if a <= 0: return False, 0
        
        vertex_x = -b / (2 * a)
        len_window = len(y)
        
        if not (len_window * 0.3 <= vertex_x <= len_window * 1.1):
            return False, a
            
        current_slope = y[-1] - y[-2]
        if current_slope <= 0: return False, a

        return True, a
    except:
        return False, 0

def get_ghost_metrics(symbol, vol_threshold):
    try:
        stock = yf.Ticker(symbol)
        df_1h = stock.history(period="6mo", interval="1h")
        if len(df_1h) < 240: return None

        # --- A. æ—¥ç·šç´šåˆ¥è™•ç† ---
        df_daily_synth = df_1h.resample('D').agg({
            'Volume': 'sum',
            'Close': 'last'
        }).dropna()
        
        df_daily_synth['MA60'] = df_daily_synth['Close'].rolling(window=60).mean()
        
        if len(df_daily_synth) < 60: return None
        
        daily_ma60_now = df_daily_synth['MA60'].iloc[-1]
        daily_ma60_prev = df_daily_synth['MA60'].iloc[-2]
        current_price_daily = df_daily_synth['Close'].iloc[-1]

        if check_daily_ma60_up and daily_ma60_now <= daily_ma60_prev: return None
        if check_price_above_daily_ma60 and current_price_daily < daily_ma60_now: return None

        avg_volume = df_daily_synth['Volume'].rolling(window=20).mean().iloc[-1]
        if avg_volume < vol_threshold: return None

        close_daily = df_daily_synth['Close']
        log_ret = np.log(close_daily / close_daily.shift(1))
        vol_30d = log_ret.rolling(window=30).std() * np.sqrt(252) * 100
        
        current_hv = vol_30d.iloc[-1]
        min_hv = vol_30d.min()
        max_hv = vol_30d.max()
        if max_hv == min_hv: return None
        hv_rank = ((current_hv - min_hv) / (max_hv - min_hv)) * 100
        
        if hv_rank > hv_threshold: return None

        # --- B. 4å°æ™‚ç´šåˆ¥è™•ç† ---
        df_4h = df_1h.resample('4h').agg({
            'Close': 'last', 
            'Volume': 'sum'
        }).dropna()
        
        if len(df_4h) < 60: return None

        df_4h['MA60'] = df_4h['Close'].rolling(window=60).mean()
        ma_segment = df_4h['MA60'].iloc[-u_sensitivity:]
        if ma_segment.isnull().values.any() or len(ma_segment) < u_sensitivity: return None
        
        current_price_4h = df_4h['Close'].iloc[-1]
        ma60_now_4h = ma_segment.iloc[-1]
        dist_pct = ((current_price_4h - ma60_now_4h) / ma60_now_4h) * 100

        if abs(dist_pct) > dist_threshold: return None 
        
        # --- C. U å‹æª¢æ¸¬ ---
        u_score = 0
        curvature = 0

        if enable_u_logic:
            is_u_shape, curv = analyze_u_shape(ma_segment)
            if not is_u_shape: return None
            if curv < min_curvature: return None
            curvature =
