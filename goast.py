import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import requests
from io import StringIO
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- 1. é é¢åŸºç¤è¨­å®š ---
st.set_page_config(page_title="å¹½éˆç­–ç•¥æƒæå™¨ (å…¨åŠŸèƒ½ç‰ˆ)", page_icon="ğŸ‘»", layout="wide")

st.title("ğŸ‘» å¹½éˆç­–ç•¥æƒæå™¨ (å…¨åŠŸèƒ½ç‰ˆ)")
st.write("""
**ç­–ç•¥ç›®æ¨™**ï¼šå°‹æ‰¾ **ä½æ³¢å‹• (HV)** ä¸” **è²¼è¿‘ 4H 60MA** çš„æ¨™çš„ï¼Œä¸¦æ”¯æ´ **Uå‹åè½‰** å½¢æ…‹è­˜åˆ¥ã€‚
""")

# --- 2. å´é‚Šæ¬„ï¼šåƒæ•¸è¨­å®šå€ ---
st.sidebar.header("ğŸ¯ å¸‚å ´èˆ‡æ•¸é‡")
market_choice = st.sidebar.radio(
    "é¸æ“‡æƒæå¸‚å ´", 
    ["S&P 500 (å¤§å‹è‚¡)", "NASDAQ 100 (ç§‘æŠ€è‚¡)", "ğŸ”¥ å…¨ç«åŠ› (å…©è€…å…¨æƒ)"],
    index=2
)
scan_limit = st.sidebar.slider("æƒææ•¸é‡ (å‰ N å¤§)", 50, 600, 200)

st.sidebar.header("âš™ï¸ ç¯©é¸æ¢ä»¶")
# ã€å·²ä¿®å¾©ã€‘HV Rank åŠ å›ä¾†äº†ï¼
hv_threshold = st.sidebar.slider("HV Rank é–€æª» (è¶Šä½è¶Šå¥½)", 10, 100, 60, help="æ•¸å€¼è¶Šä½ä»£è¡¨æ³¢å‹•è¶Šå° (çµå†°)ï¼Œé©åˆ Step 1 é€²å ´ã€‚")
min_vol_m = st.sidebar.slider("æœ€å°æ—¥å‡é‡ (ç™¾è¬è‚¡)", 1, 20, 3) 
min_volume_threshold = min_vol_m * 1000000

# --- Uå‹æˆ°æ³•é–‹é—œ ---
st.sidebar.header("ğŸ“ˆ 4å°æ™‚ Uå‹æˆ°æ³•")
enable_u_logic = st.sidebar.checkbox("âœ… å•Ÿç”¨ã€ŒUå‹æ•¸å­¸æ“¬åˆã€éæ¿¾", value=True, help="æ‰“å‹¾ï¼šåš´æ ¼ç¯©é¸å®Œç¾ U å‹ã€‚\nå–æ¶ˆï¼šåªç¯©é¸ä¹–é›¢ç‡ï¼Œä¸çœ‹å½¢ç‹€ã€‚")

dist_threshold = st.sidebar.slider("è·é›¢ 60MA ç¯„åœ (%)", 0.0, 50.0, 8.0, step=0.5)

if enable_u_logic:
    u_sensitivity = st.sidebar.slider("Uå‹æ•æ„Ÿåº¦ (Lookback)", 20, 60, 30)
    min_curvature = st.sidebar.slider("æœ€å°å½æ›²åº¦", 0.0, 0.1, 0.003, format="%.3f")
else:
    u_sensitivity = 30
    min_curvature = 0.003

st.sidebar.markdown("---")
max_workers = st.sidebar.slider("ğŸš€ å¹³è¡Œé‹ç®—æ ¸å¿ƒæ•¸", 1, 32, 16)

# --- 3. æ ¸å¿ƒå‡½æ•¸ ---

@st.cache_data(ttl=3600)
def get_sp500_tickers():
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        response = requests.get(url, headers=headers)
        df = pd.read_html(StringIO(response.text))[0]
        tickers = df['Symbol'].tolist()
        return [t.replace('.', '-') for t in tickers]
    except:
        return []

@st.cache_data(ttl=3600)
def get_nasdaq100_tickers():
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        url = "https://en.wikipedia.org/wiki/Nasdaq-100"
        response = requests.get(url, headers=headers)
        dfs = pd.read_html(StringIO(response.text))
